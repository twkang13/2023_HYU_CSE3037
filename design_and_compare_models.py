# -*- coding: utf-8 -*-
"""Design_and_Compare_models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-cDYPgH67F31Cxh0FNj4gmcoZZKe5Db6
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split

data_origin = pd.read_csv('./auto-mpg.csv',index_col='car name')

# dataset에 bias column 추가
data_origin['bias'] = 1

# 결측값 제거 및 type casting
data_origin = data_origin[data_origin.horsepower != '?']
data_origin.horsepower = data_origin.horsepower.astype('float')

print(data_origin.head(10))

# data scaling
def scale(a):
    b = (a-a.min())/(a.max()-a.min())
    return b

data = data_origin.copy()

# data별로 scaling 정도 조정 필요
data['displacement'] = scale(data_origin['displacement'])
data['horsepower'] = scale(data_origin['horsepower'])
data['acceleration'] = scale(data_origin['acceleration'])
data['weight'] = scale(data_origin['weight'])

print(data.head(10))

# dataset을 X와 y로 분할
y_t = data['mpg']
y_t = np.array(y_t).reshape((len(y_t),1))
y_t = pd.DataFrame(y_t, index=data.index)
y_t.columns = ['mpg']

X_t = data.drop('mpg', axis=1)

# train data와 test data로 분할
X_train_t, X_test_t, y_train_t, y_test_t= train_test_split(X_t, y_t, test_size = 0.2, shuffle=False, random_state=1004)

print('X_train_t shape:', X_train_t.shape)
print('X_test_t shape:', X_test_t.shape)
print('y_train_t shape:', y_train_t.shape)
print('y_test_t shape:', y_test_t.shape)

# 식에 맞도록 차원 변화 (NxD에서 DxN으로)
X_train = X_train_t.T
X_test = X_test_t.T
y_train = y_train_t.T
y_test = y_test_t.T

# dataset의 차원
print('X_train shape:', X_train.shape)
print('X_test shape:',X_test.shape)
print('y_train shape:',y_train.shape)
print('y_test shape:',y_test.shape)

X_train.head(10)

# 성능 테스트 위해 MSE 정의
def mean_squared_error(y_true, prediction):
  mse = np.mean((y_true - prediction) ** 2)
  return np.mean(mse)

# 성능 테스트 위해 실제 데이터와 예측 데이터의 위치 보여주는 그래프 그리는 함수 작성
def prediction_solution(y_true, prediction, X):
  N = X.shape[1]
  x = np.arange(N)

  x = np.reshape(x, (1,79))
  y_true = np.reshape(y_true, (1,79))
  prediction = np.reshape(prediction, (1,79))
  
  # x축에 실제 데이터, y축에 예측 데이터
  plt.plot(y_true, prediction, 'bo')

  plt.xlabel('y_test')
  plt.ylabel('prediction')

  plt.axis([15,50,15,50])

  plt.legend()
  plt.show()

# MSE, 성능 테스트 위한 비교군
class MSE:
  # Learning rate, iteration, parameter 설정
  def __init__(self,learning_rate=0.00001,iter=100000):
    self.learning_rate = learning_rate
    self.iter = iter
    self.w = None

  # Learning with Gradient Descent
  def fit(self, X, y):
    # parameter 초기화
    rows, columns = X.shape
    self.w = np.zeros(rows)
    self.w = np.array(self.w).reshape((len(self.w),1))
      
    # Data size
    N = len(X)

    # Closed-form Solution
    p1 = np.dot(X, X.T)
    pw = np.dot(np.linalg.inv(p1), X)
    self.w = np.dot(pw, y.T)

  def predict(self, x):
    y_predict = np.dot(self.w.T, x)
    return y_predict.round(1)

# MSLE
class MSLE:
  # Learning rate, iteration, parameter 설정
  def __init__(self,learning_rate=0.00001,iter=100000):
    self.learning_rate = learning_rate
    self.iter = iter
    self.w = None

  # Learning with Gradient Descent
  def fit(self, X, y):
    # parameter 초기화
    rows, columns = X.shape
    self.w = np.zeros(rows)
    self.w = np.array(self.w).reshape((len(self.w),1))
      
    # Data size
    N = len(X)

    for i in range(self.iter):
      y_hat = np.dot(self.w.T, X)

      # Loss function의 미분값 계산
      pl = np.log(y+1) - np.log(y_hat+1)
      dpl = X/(y_hat+1)
      dL = -1 * (2/N) * np.dot(dpl, pl.T)

      # parameter update
      self.w -= (self.learning_rate * dL)

  def predict(self, x):
    y_predict = np.dot(self.w.T, x)
    return y_predict.round(1)

# MLE
class MLE:
  # Learning rate, iteration, parameter 설정
  def __init__(self,learning_rate=0.000001,iter=100000):
    self.learning_rate = learning_rate
    self.iter = iter
    self.w = None
    self.var = 0

  # Learning with Gradient Descent
  def fit(self, X, y, var):
    # parameter 초기화
    rows, columns = X.shape
    self.w = np.zeros(rows)
    self.w = np.array(self.w).reshape((len(self.w),1))

    # variance 초기화
    self.var = var
      
    # Data size
    N = len(X)

    for i in range(self.iter):
      y_hat = np.dot(self.w.T, X)

      # Loss function의 미분값 계산
      pl = y - np.dot(self.w.T, X)
      dL = np.dot(X, pl.T) / var

      # parameter update
      self.w += (self.learning_rate * dL)

  def predict(self, x):
    y_predict = np.dot(self.w.T, x)
    return y_predict.round(1)

#MAP
class MAP:
  # Learning rate, iteration, parameter, variance 설정
  def __init__(self, learning_rate=0.000001, iter=100000):
    self.learning_rate = learning_rate
    self.iter = iter
    self.w = None
    self.var_w = None
    self.var_model = None

  def fit(self, X, y, var_model, var_w):
    # parameter 초기화
    rows, columns = X.shape
    self.w = np.zeros(rows)
    self.w = np.array(self.w).reshape((len(self.w),1))

    # variance 초기화
    self.var_model = var_model
    self.var_w = var_w

    # Data size
    N = len(X)

    for i in range(self.iter):
      y_hat = np.dot(self.w.T, X)

      # Loss function의 미분값 계산
      pl = y - np.dot(self.w.T, X)
      dM = (np.dot(X, pl.T) / self.var_model) - (self.w / self.var_w)

      # parameter update
      self.w += (self.learning_rate * dM)

  def predict(self, x):
    y_predict = np.dot(self.w.T, x)
    return y_predict.round(1)

mse = MSE()
mse.fit(X_train, y_train)
prediction = mse.predict(X_test)

print(y_test.values)
print()
print(prediction)
print()

mse = mean_squared_error(y_test, prediction)
print("MSE: {}".format(mse))

prediction_solution(y_test, prediction, X_test)

msle = MSLE()
msle.fit(X_train, y_train)
prediction = msle.predict(X_test)

print(y_test.values)
print()
print(prediction)
print()

mse = mean_squared_error(y_test, prediction)
print("MSE: {}".format(mse))

prediction_solution(y_test, prediction, X_test)

mle = MLE()
mle.fit(X_train, y_train, 1)
prediction = mle.predict(X_test)

print(y_test.values)
print()
print(prediction)
print()

mse = mean_squared_error(y_test, prediction)
print("MSE: {}".format(mse))

prediction_solution(y_test, prediction, X_test)

map = MAP()
map.fit(X_train, y_train, 1, 1)
prediction = map.predict(X_test)

print(y_test.values)
print()
print(prediction)
print()

mse = mean_squared_error(y_test,prediction)
print("MSE: {}".format(mse))

prediction_solution(y_test, prediction, X_test)